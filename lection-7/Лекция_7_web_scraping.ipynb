{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8zzbBiIsauy"
      },
      "source": [
        "**Веб-скрейпинг** (или скрепинг, или скрапинг) — это технология получения веб-данных путем извлечения их со страниц веб-ресурсов.  \n",
        "Веб-скрейпинг объединяет в себе функции краулера (обход сайта и сбор данных) и парсера (анализ содержимого).  \n",
        "Но чаще для обозначения всего процесса сбора и анализа информации используют слово **парсер**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iMSTDi9sau0"
      },
      "source": [
        "### Requests\n",
        "Python Requests — это библиотека, которая создана для быстрой и простой работы с запросами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlX24Z9ksau0"
      },
      "source": [
        "GET - запрашивает представление ресурса. Запросы с использованием этого метода могут только извлекать данные.\n",
        "\n",
        "HEAD - запрашивает ресурс так же, как и метод GET, но без тела ответа.\n",
        "\n",
        "POST - используется для отправки сущностей к определённому ресурсу. Часто вызывает изменение состояния или какие-то побочные эффекты на сервере.\n",
        "\n",
        "PUT - заменяет все текущие представления ресурса данными запроса.\n",
        "\n",
        "DELETE - удаляет указанный ресурс.\n",
        "\n",
        "PATCH - используется для частичного изменения ресурса."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка\n",
        "!pip install requests"
      ],
      "metadata": {
        "id": "DKywXOFL6DEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezdpX44wsau1"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ссылка на ресурс для теста запросов\n",
        "url = \"https://httpbin.org/get\""
      ],
      "metadata": {
        "id": "1BODnnPlCqes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url)"
      ],
      "metadata": {
        "id": "ljh4MtLvCXFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.text"
      ],
      "metadata": {
        "id": "1S7PjZOVCwvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP6S7Mcpsau1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "HTTP headers позволяют клиенту и серверу передавать дополнительную информацию\n",
        "с помощью HTTP-запроса или ответа.\n",
        "'User-Agent' представляет клиентскую программу, инициирующую запрос.\n",
        "\"\"\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Custom Agent\",\n",
        "    \"Content-Type\": \"application/json; charset=utf-8\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_jS9PlVsau1"
      },
      "outputs": [],
      "source": [
        "# get запрос без headers\n",
        "requests.get(url).json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzg--mR1sau2"
      },
      "outputs": [],
      "source": [
        "# get запрос с headers\n",
        "# в качестве параметров в url передается словарь {\"key\": \"value\"}\n",
        "response = requests.get(url, headers=headers, params={\"key\": \"value\"})\n",
        "print(response.json())\n",
        "print(response.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMPm2rdtsau2"
      },
      "outputs": [],
      "source": [
        "# post запрос\n",
        "data = {'somekey': 'somevalue'}\n",
        "\n",
        "# Словарь data автоматически кодируется как HTML форма\n",
        "response = requests.post(\"https://httpbin.org/post\", data=data)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBtens5Asau2"
      },
      "outputs": [],
      "source": [
        "# get запрос к официальному сайту Python\n",
        "python_url = \"https://www.python.org\"\n",
        "response = requests.get(python_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irq698uDsau3"
      },
      "outputs": [],
      "source": [
        "# Заголовки ответа\n",
        "response.headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1js39W_3sau3"
      },
      "outputs": [],
      "source": [
        "# Содержимое ответа в unicode\n",
        "response.text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.status_code"
      ],
      "metadata": {
        "id": "LT8kcAE_mMNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQMLd1pesau3"
      },
      "source": [
        "### Beautiful Soup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4svfhh1sau3"
      },
      "source": [
        "BeautifulSoup4 (bs4) - это библиотека Python для извлечения данных из файлов HTML и XML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9FJOWUysau3"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs6rjgiQsau3"
      },
      "outputs": [],
      "source": [
        "# get запрос к официальному сайту Python\n",
        "url = \"https://www.python.org\"\n",
        "response = requests.get(url)\n",
        "response.status_code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWmWStGYsau3"
      },
      "source": [
        "Чтобы разобрать HTML-документ, необходимо передать его в конструктор класса **BeautifulSoup()**.  \n",
        "Можно передать строку или открытый дескриптор файла."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Q5HbWHqcsau4"
      },
      "outputs": [],
      "source": [
        "# Поддерживает несколько видов парсеров: html.parser, lxml, html5lib и xml\n",
        "bs = BeautifulSoup(response.text, \"lxml\")\n",
        "print(bs.prettify())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2CJ7n6Nsau4"
      },
      "outputs": [],
      "source": [
        "# Получаем информацию отдельно по тегам\n",
        "print(bs.title)\n",
        "# можно использовать метод text для получения содержимого тега\n",
        "print(bs.title.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ehoruxaWumV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avDElHVWsau4"
      },
      "source": [
        "Методы поиска тегов:  \n",
        "**find()** возвращает первый элемент по переданным фильтрующим аргументам.  \n",
        "**find_all()** просматривает и извлекает ВСЕХ потомков тега, которые соответствуют переданным фильтрующим аргументам.  \n",
        "\n",
        "**Аргументы:**  \n",
        "**name** - фильтр по имени HTML-тега, может быть:\n",
        " - строкой с именем HTML-тега,\n",
        " - списком с несколькими именами HTML-тегов,\n",
        " - объектом регулярного выражения,\n",
        " - значением bool,\n",
        " - функцией.\n",
        "\n",
        "**attrs** - словарь, с атрибутами HTML-тега в виде {\"class\": \"sister\"},  \n",
        "**recursive** - отвечает за рекурсивный просмотр потомков, по умолчанию True,  \n",
        "**string** - ищет совпадение в тексте HTML-документа, а не в тегах. Принимаемые значения такие же, как у аргумента name.  \n",
        "**limit** - целое число, ограничивает максимальное количество совпадений.  \n",
        "****kwargs** - фильтр по атрибутам HTML-тега. Принимаемые значения такие же, как у аргумента name.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkjcllH2sau4"
      },
      "outputs": [],
      "source": [
        "# получаем содержимое тега со спсиком новостей\n",
        "latest_news = bs.find('div', class_='medium-widget blog-widget')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l1PNgPQsau4"
      },
      "outputs": [],
      "source": [
        "type(latest_news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-TFCPaosau4"
      },
      "outputs": [],
      "source": [
        "# далее можно применить find_all для получения списка элементов li\n",
        "data = [{'date': li.time.text, 'news': li.a.text} for li in latest_news.find_all('li')]\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPIl3lnZsau4"
      },
      "outputs": [],
      "source": [
        "# Для дальнейше обработки полученные данные можно представить в виде DataFrame\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4HHtMaHsau5"
      },
      "outputs": [],
      "source": [
        "# Запись результата в файл\n",
        "import csv\n",
        "with open('news.csv', 'w', newline='', encoding='utf8') as csvfile:\n",
        "    fieldnames = ['date', 'news']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq0A_awCsau5"
      },
      "source": [
        "### icrawler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6cC-xUPsau5"
      },
      "source": [
        "**icrawler** предоставляет удобные инструменты для скачивания изображений из различных интернет-ресурсов. Этот модуль поддерживает несколько источников, таких как Google Images, Bing Images, Flickr и другие."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfqctKBUsau5"
      },
      "source": [
        "Модуль **icrawler** включает в себя несколько классов, каждый из которых предназначен для работы с определенным источником изображений. Вот несколько ключевых элементов:\n",
        "1. GoogleImageCrawler\n",
        "2. BingImageCrawler\n",
        "3. FlickrImageCrawler\n",
        "4. GreedyImageCrawler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler"
      ],
      "metadata": {
        "id": "eoer-2DEXiqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4477Skhsau5"
      },
      "outputs": [],
      "source": [
        "# Импорт нужных классов\n",
        "from icrawler.builtin import (\n",
        "    GoogleImageCrawler,\n",
        "    GreedyImageCrawler\n",
        ")\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsVOtUHIsau5"
      },
      "outputs": [],
      "source": [
        "# Cкачивание 5 изображений из Google Images\n",
        "print(\"start testing GoogleImageCrawler\")\n",
        "google_images_dir = \"images/google\"\n",
        "google_crawler = GoogleImageCrawler(\n",
        "    downloader_threads=4, storage={\"root_dir\": google_images_dir}, log_level=logging.INFO\n",
        ")\n",
        "search_filters = dict(size=\"large\", color=\"orange\", license=\"commercial,modify\", date=(None, (2017, 11, 30)))\n",
        "google_crawler.crawl(\"cat\", filters=search_filters, max_num=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOS7PG0fsau5"
      },
      "outputs": [],
      "source": [
        "# Cкачивание 5 изображений из заданного по url ресурса\n",
        "print(\"start testing GreedyImageCrawler\")\n",
        "greedy_images_dir = \"images/greedy\"\n",
        "greedy_crawler = GreedyImageCrawler(parser_threads=4, storage={\"root_dir\": greedy_images_dir})\n",
        "greedy_crawler.crawl(\"https://mixkit.co/\", max_num=5, min_size=(100, 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_5FRbahsau5"
      },
      "source": [
        "#### Полезные ссылки:\n",
        "Википедия: https://ru.wikipedia.org/wiki/Веб-скрейпинг  \n",
        "Документация Requests: https://requests.readthedocs.io/en/latest/  \n",
        "Документация BeautifulSoup4: https://www.crummy.com/software/BeautifulSoup/bs4/doc/  \n",
        "Документация icrowler: http://icrawler.readthedocs.io/  \n",
        "HTTP headers: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}